2023-01-03T10:37:47 | INFO | mmf : Logging to: ../exp/checkpoints_10Epoch_w_act_exp/Prediction_GT_Sem/train.log
2023-01-03T10:37:47 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=projects/nssr/atm/defaults.yaml', 'datasets=star_nssr', 'model=action_transition_model', 'run_type=train', 'dataset_config.star_nssr.qtype=Prediction', 'training.evaluation_interval=500', 'training.batch_size=64', 'training.max_epochs=80', 'training.checkpoint_interval=500', 'env.save_dir=../exp/checkpoints_10Epoch_w_act_exp/Prediction_GT_Sem', 'dataset_config.star_nssr.train_graph=GT', 'dataset_config.star_nssr.val_graph=Swin_STTrans_10Epoch', 'dataset_config.star_nssr.symbolic=False', 'dataset_config.star_nssr.semantic=True', 'dataset_config.star_nssr.visual=False', 'dataset_config.star_nssr.graph_type=SGDet'])
2023-01-03T10:37:47 | INFO | mmf_cli.run : Torch version: 1.6.0a0+445c276
2023-01-03T10:37:47 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla V100-SXM2-32GB
2023-01-03T10:37:47 | INFO | mmf_cli.run : Using seed 50150642
2023-01-03T10:37:47 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-01-03T10:37:52 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No 'max_length' parameter in Processor's configuration. Setting to 50.
  builtin_warn(*args, **kwargs)

2023-01-03T10:37:52 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No 'max_length' parameter in Processor's configuration. Setting to 50.
  builtin_warn(*args, **kwargs)

2023-01-03T10:37:53 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-01-03T10:37:54 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No losses are defined in model configuration. You are expected to return loss in your return dict from forward.
  builtin_warn(*args, **kwargs)

2023-01-03T10:37:54 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No losses are defined in model configuration. You are expected to return loss in your return dict from forward.
  builtin_warn(*args, **kwargs)

2023-01-03T10:37:54 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-01-03T10:37:54 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-01-03T10:37:54 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  builtin_warn(*args, **kwargs)

2023-01-03T10:37:54 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  builtin_warn(*args, **kwargs)

2023-01-03T10:37:54 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  builtin_warn(*args, **kwargs)

2023-01-03T10:37:54 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  builtin_warn(*args, **kwargs)

2023-01-03T10:37:54 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-01-03T10:37:54 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: Both max_updates and max_epochs are specified. Favoring max_epochs: 80
  builtin_warn(*args, **kwargs)

2023-01-03T10:37:54 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: Both max_updates and max_epochs are specified. Favoring max_epochs: 80
  builtin_warn(*args, **kwargs)

2023-01-03T10:37:54 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-01-03T10:37:55 | INFO | torchtext.vocab : Loading vectors from /home/bowu/.cache/torch/mmf/glove.6B.300d.txt.pt
2023-01-03T10:37:55 | INFO | torchtext.vocab : Loading vectors from /home/bowu/.cache/torch/mmf/glove.6B.300d.txt.pt
2023-01-03T10:38:03 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: 'losses' already present in model output. No calculation will be done in base model.
  builtin_warn(*args, **kwargs)

2023-01-03T10:38:03 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: 'losses' already present in model output. No calculation will be done in base model.
  builtin_warn(*args, **kwargs)

2023-01-03T10:38:03 | WARNING | py.warnings : /nobackup/users/bowu/anaconda3/envs/mmf/lib/python3.6/site-packages/transformers/optimization.py:146: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /home/florin/anaconda3/conda-bld/pytorch-base_1604496080370/work/torch/csrc/utils/python_arg_parser.cpp:766.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)

2023-01-03T10:38:03 | WARNING | py.warnings : /nobackup/users/bowu/anaconda3/envs/mmf/lib/python3.6/site-packages/transformers/optimization.py:146: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /home/florin/anaconda3/conda-bld/pytorch-base_1604496080370/work/torch/csrc/utils/python_arg_parser.cpp:766.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)

2023-01-03T10:49:14 | INFO | mmf.trainers.callbacks.logistics : progress: 100/20800, star/train/masked_act_loss: 0.0000, star/train/masked_act_loss/avg: 0.0000, star/train/masked_obj1_loss: 0.0000, star/train/masked_obj1_loss/avg: 0.0000, star/train/masked_obj2_loss: 0.0000, star/train/masked_obj2_loss/avg: 0.0000, star/train/masked_rel_loss: 2.8399, star/train/masked_rel_loss/avg: 2.8399, train/total_loss: 2.8399, train/total_loss/avg: 2.8399, max mem: 2320.0, experiment: action_transition_model, epoch: 2, num_updates: 100, iterations: 100, max_updates: 20800, lr: 0.00002, ups: 0.15, time: 11m 19s 879ms, time_since_start: 11m 19s 906ms, eta: 39h 05m 35s 053ms
2023-01-03T10:59:51 | INFO | mmf.trainers.callbacks.logistics : progress: 200/20800, star/train/masked_act_loss: 0.0000, star/train/masked_act_loss/avg: 0.0000, star/train/masked_obj1_loss: 0.0000, star/train/masked_obj1_loss/avg: 0.0000, star/train/masked_obj2_loss: 0.0000, star/train/masked_obj2_loss/avg: 0.0000, star/train/masked_rel_loss: 2.4695, star/train/masked_rel_loss/avg: 2.6547, train/total_loss: 2.4695, train/total_loss/avg: 2.6547, max mem: 2320.0, experiment: action_transition_model, epoch: 4, num_updates: 200, iterations: 200, max_updates: 20800, lr: 0.00003, ups: 0.16, time: 10m 36s 776ms, time_since_start: 21m 56s 682ms, eta: 36h 26m 15s 885ms
2023-01-03T11:10:11 | INFO | mmf.trainers.callbacks.logistics : progress: 300/20800, star/train/masked_act_loss: 0.0000, star/train/masked_act_loss/avg: 0.0000, star/train/masked_obj1_loss: 0.0000, star/train/masked_obj1_loss/avg: 0.0000, star/train/masked_obj2_loss: 0.0000, star/train/masked_obj2_loss/avg: 0.0000, star/train/masked_rel_loss: 2.4695, star/train/masked_rel_loss/avg: 2.4577, train/total_loss: 2.4695, train/total_loss/avg: 2.4577, max mem: 2320.0, experiment: action_transition_model, epoch: 5, num_updates: 300, iterations: 300, max_updates: 20800, lr: 0.00004, ups: 0.16, time: 10m 19s 522ms, time_since_start: 32m 16s 205ms, eta: 35h 16m 42s 181ms
2023-01-03T11:21:07 | INFO | mmf.trainers.callbacks.logistics : progress: 400/20800, star/train/masked_act_loss: 0.0000, star/train/masked_act_loss/avg: 0.0000, star/train/masked_obj1_loss: 0.0000, star/train/masked_obj1_loss/avg: 0.0000, star/train/masked_obj2_loss: 0.0000, star/train/masked_obj2_loss/avg: 0.0000, star/train/masked_rel_loss: 2.0637, star/train/masked_rel_loss/avg: 2.3019, train/total_loss: 2.0637, train/total_loss/avg: 2.3019, max mem: 2320.0, experiment: action_transition_model, epoch: 7, num_updates: 400, iterations: 400, max_updates: 20800, lr: 0.00005, ups: 0.15, time: 10m 56s 118ms, time_since_start: 43m 12s 323ms, eta: 37h 10m 48s 236ms
2023-01-03T11:31:57 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-01-03T11:31:57 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

2023-01-03T11:31:57 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

2023-01-03T11:31:58 | INFO | mmf.trainers.callbacks.logistics : progress: 500/20800, star/train/masked_act_loss: 0.0000, star/train/masked_act_loss/avg: 0.0000, star/train/masked_obj1_loss: 0.0000, star/train/masked_obj1_loss/avg: 0.0000, star/train/masked_obj2_loss: 0.0000, star/train/masked_obj2_loss/avg: 0.0000, star/train/masked_rel_loss: 2.0637, star/train/masked_rel_loss/avg: 2.2253, train/total_loss: 2.0637, train/total_loss/avg: 2.2253, max mem: 2320.0, experiment: action_transition_model, epoch: 8, num_updates: 500, iterations: 500, max_updates: 20800, lr: 0.00006, ups: 0.15, time: 10m 51s 081ms, time_since_start: 54m 03s 405ms, eta: 36h 42m 49s 634ms
2023-01-03T11:31:58 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
