2023-01-03T10:34:56 | INFO | mmf : Logging to: ../exp/checkpoints_10Epoch_w_act_exp/Interaction_GT_Sem/train.log
2023-01-03T10:34:56 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=projects/nssr/atm/defaults.yaml', 'datasets=star_nssr', 'model=action_transition_model', 'run_type=train', 'dataset_config.star_nssr.qtype=Interaction', 'training.evaluation_interval=500', 'training.batch_size=96', 'training.max_epochs=50', 'training.checkpoint_interval=500', 'env.save_dir=../exp/checkpoints_10Epoch_w_act_exp/Interaction_GT_Sem', 'dataset_config.star_nssr.train_graph=GT', 'dataset_config.star_nssr.val_graph=Swin_STTrans_10Epoch', 'dataset_config.star_nssr.symbolic=False', 'dataset_config.star_nssr.semantic=True', 'dataset_config.star_nssr.visual=False', 'dataset_config.star_nssr.graph_type=SGDet'])
2023-01-03T10:34:56 | INFO | mmf_cli.run : Torch version: 1.6.0a0+445c276
2023-01-03T10:34:56 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla V100-SXM2-32GB
2023-01-03T10:34:56 | INFO | mmf_cli.run : Using seed 59570764
2023-01-03T10:34:56 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-01-03T10:35:03 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No 'max_length' parameter in Processor's configuration. Setting to 50.
  builtin_warn(*args, **kwargs)

2023-01-03T10:35:03 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No 'max_length' parameter in Processor's configuration. Setting to 50.
  builtin_warn(*args, **kwargs)

2023-01-03T10:35:06 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-01-03T10:35:07 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No losses are defined in model configuration. You are expected to return loss in your return dict from forward.
  builtin_warn(*args, **kwargs)

2023-01-03T10:35:07 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No losses are defined in model configuration. You are expected to return loss in your return dict from forward.
  builtin_warn(*args, **kwargs)

2023-01-03T10:35:07 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-01-03T10:35:07 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-01-03T10:35:07 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  builtin_warn(*args, **kwargs)

2023-01-03T10:35:07 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  builtin_warn(*args, **kwargs)

2023-01-03T10:35:07 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  builtin_warn(*args, **kwargs)

2023-01-03T10:35:07 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  builtin_warn(*args, **kwargs)

2023-01-03T10:35:07 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-01-03T10:35:07 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: Both max_updates and max_epochs are specified. Favoring max_epochs: 50
  builtin_warn(*args, **kwargs)

2023-01-03T10:35:07 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: Both max_updates and max_epochs are specified. Favoring max_epochs: 50
  builtin_warn(*args, **kwargs)

2023-01-03T10:35:07 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-01-03T10:35:07 | INFO | torchtext.vocab : Loading vectors from /home/bowu/.cache/torch/mmf/glove.6B.300d.txt.pt
2023-01-03T10:35:08 | INFO | torchtext.vocab : Loading vectors from /home/bowu/.cache/torch/mmf/glove.6B.300d.txt.pt
2023-01-03T10:35:17 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: 'losses' already present in model output. No calculation will be done in base model.
  builtin_warn(*args, **kwargs)

2023-01-03T10:35:17 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: 'losses' already present in model output. No calculation will be done in base model.
  builtin_warn(*args, **kwargs)

2023-01-03T10:35:18 | WARNING | py.warnings : /nobackup/users/bowu/anaconda3/envs/mmf/lib/python3.6/site-packages/transformers/optimization.py:146: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /home/florin/anaconda3/conda-bld/pytorch-base_1604496080370/work/torch/csrc/utils/python_arg_parser.cpp:766.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)

2023-01-03T10:35:18 | WARNING | py.warnings : /nobackup/users/bowu/anaconda3/envs/mmf/lib/python3.6/site-packages/transformers/optimization.py:146: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /home/florin/anaconda3/conda-bld/pytorch-base_1604496080370/work/torch/csrc/utils/python_arg_parser.cpp:766.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)

2023-01-03T10:50:01 | INFO | mmf.trainers.callbacks.logistics : progress: 100/34000, star/train/masked_act_loss: 0.0000, star/train/masked_act_loss/avg: 0.0000, star/train/masked_obj1_loss: 0.0000, star/train/masked_obj1_loss/avg: 0.0000, star/train/masked_obj2_loss: 0.0000, star/train/masked_obj2_loss/avg: 0.0000, star/train/masked_rel_loss: 2.9827, star/train/masked_rel_loss/avg: 2.9827, train/total_loss: 2.9827, train/total_loss/avg: 2.9827, max mem: 3374.0, experiment: action_transition_model, epoch: 1, num_updates: 100, iterations: 100, max_updates: 34000, lr: 0.00002, ups: 0.11, time: 14m 54s 180ms, time_since_start: 14m 54s 247ms, eta: 84h 22m 13s 453ms
2023-01-03T11:03:51 | INFO | mmf.trainers.callbacks.logistics : progress: 200/34000, star/train/masked_act_loss: 0.0000, star/train/masked_act_loss/avg: 0.0000, star/train/masked_obj1_loss: 0.0000, star/train/masked_obj1_loss/avg: 0.0000, star/train/masked_obj2_loss: 0.0000, star/train/masked_obj2_loss/avg: 0.0000, star/train/masked_rel_loss: 2.4690, star/train/masked_rel_loss/avg: 2.7258, train/total_loss: 2.4690, train/total_loss/avg: 2.7258, max mem: 3374.0, experiment: action_transition_model, epoch: 2, num_updates: 200, iterations: 200, max_updates: 34000, lr: 0.00003, ups: 0.12, time: 13m 50s 182ms, time_since_start: 28m 44s 430ms, eta: 78h 06m 03s 032ms
2023-01-03T11:17:50 | INFO | mmf.trainers.callbacks.logistics : progress: 300/34000, star/train/masked_act_loss: 0.0000, star/train/masked_act_loss/avg: 0.0000, star/train/masked_obj1_loss: 0.0000, star/train/masked_obj1_loss/avg: 0.0000, star/train/masked_obj2_loss: 0.0000, star/train/masked_obj2_loss/avg: 0.0000, star/train/masked_rel_loss: 2.4690, star/train/masked_rel_loss/avg: 2.4965, train/total_loss: 2.4690, train/total_loss/avg: 2.4965, max mem: 3374.0, experiment: action_transition_model, epoch: 2, num_updates: 300, iterations: 300, max_updates: 34000, lr: 0.00004, ups: 0.12, time: 13m 59s 229ms, time_since_start: 42m 43s 660ms, eta: 78h 43m 06s 009ms
2023-01-03T11:32:00 | INFO | mmf.trainers.callbacks.logistics : progress: 400/34000, star/train/masked_act_loss: 0.0000, star/train/masked_act_loss/avg: 0.0000, star/train/masked_obj1_loss: 0.0000, star/train/masked_obj1_loss/avg: 0.0000, star/train/masked_obj2_loss: 0.0000, star/train/masked_obj2_loss/avg: 0.0000, star/train/masked_rel_loss: 2.0377, star/train/masked_rel_loss/avg: 2.3323, train/total_loss: 2.0377, train/total_loss/avg: 2.3323, max mem: 3374.0, experiment: action_transition_model, epoch: 3, num_updates: 400, iterations: 400, max_updates: 34000, lr: 0.00005, ups: 0.12, time: 14m 09s 130ms, time_since_start: 56m 52s 790ms, eta: 79h 24m 38s 352ms
2023-01-03T11:46:22 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-01-03T11:46:22 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

2023-01-03T11:46:22 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

2023-01-03T11:46:23 | INFO | mmf.trainers.callbacks.logistics : progress: 500/34000, star/train/masked_act_loss: 0.0000, star/train/masked_act_loss/avg: 0.0000, star/train/masked_obj1_loss: 0.0000, star/train/masked_obj1_loss/avg: 0.0000, star/train/masked_obj2_loss: 0.0000, star/train/masked_obj2_loss/avg: 0.0000, star/train/masked_rel_loss: 2.0377, star/train/masked_rel_loss/avg: 2.1778, train/total_loss: 2.0377, train/total_loss/avg: 2.1778, max mem: 3374.0, experiment: action_transition_model, epoch: 3, num_updates: 500, iterations: 500, max_updates: 34000, lr: 0.00006, ups: 0.12, time: 14m 23s 183ms, time_since_start: 01h 11m 15s 973ms, eta: 80h 29m 04s 656ms
2023-01-03T11:46:23 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-01-04T22:35:20 | INFO | mmf : Logging to: ../exp/checkpoints_10Epoch_w_act_exp/Interaction_GT_Sem/train.log
2023-01-04T22:35:20 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=projects/nssr/atm/defaults.yaml', 'datasets=star_nssr', 'model=action_transition_model', 'run_type=train', 'dataset_config.star_nssr.qtype=Interaction', 'training.evaluation_interval=500', 'training.batch_size=96', 'training.max_epochs=50', 'training.checkpoint_interval=500', 'env.save_dir=../exp/checkpoints_10Epoch_w_act_exp/Interaction_GT_Sem', 'dataset_config.star_nssr.train_graph=GT', 'dataset_config.star_nssr.val_graph=Swin_STTrans_10Epoch', 'dataset_config.star_nssr.symbolic=False', 'dataset_config.star_nssr.semantic=True', 'dataset_config.star_nssr.visual=False', 'dataset_config.star_nssr.graph_type=SGDet'])
2023-01-04T22:35:20 | INFO | mmf_cli.run : Torch version: 1.6.0a0+445c276
2023-01-04T22:35:20 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla V100-SXM2-32GB
2023-01-04T22:35:20 | INFO | mmf_cli.run : Using seed 23851649
2023-01-04T22:35:20 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-01-04T22:35:27 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No 'max_length' parameter in Processor's configuration. Setting to 50.
  builtin_warn(*args, **kwargs)

2023-01-04T22:35:27 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No 'max_length' parameter in Processor's configuration. Setting to 50.
  builtin_warn(*args, **kwargs)

2023-01-04T22:35:29 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-01-04T22:35:30 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No losses are defined in model configuration. You are expected to return loss in your return dict from forward.
  builtin_warn(*args, **kwargs)

2023-01-04T22:35:30 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No losses are defined in model configuration. You are expected to return loss in your return dict from forward.
  builtin_warn(*args, **kwargs)

2023-01-04T22:35:30 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-01-04T22:35:30 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-01-04T22:35:31 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  builtin_warn(*args, **kwargs)

2023-01-04T22:35:31 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: No type for scheduler specified even though lr_scheduler is True, setting default to 'Pythia'
  builtin_warn(*args, **kwargs)

2023-01-04T22:35:31 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  builtin_warn(*args, **kwargs)

2023-01-04T22:35:31 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: scheduler attributes has no params defined, defaulting to {}.
  builtin_warn(*args, **kwargs)

2023-01-04T22:35:31 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-01-04T22:35:31 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: Both max_updates and max_epochs are specified. Favoring max_epochs: 50
  builtin_warn(*args, **kwargs)

2023-01-04T22:35:31 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: Both max_updates and max_epochs are specified. Favoring max_epochs: 50
  builtin_warn(*args, **kwargs)

2023-01-04T22:35:31 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-01-04T22:35:31 | INFO | torchtext.vocab : Loading vectors from /home/bowu/.cache/torch/mmf/glove.6B.300d.txt.pt
2023-01-04T22:35:31 | INFO | torchtext.vocab : Loading vectors from /home/bowu/.cache/torch/mmf/glove.6B.300d.txt.pt
2023-01-04T22:35:40 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: 'losses' already present in model output. No calculation will be done in base model.
  builtin_warn(*args, **kwargs)

2023-01-04T22:35:40 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: 'losses' already present in model output. No calculation will be done in base model.
  builtin_warn(*args, **kwargs)

2023-01-04T22:35:40 | WARNING | py.warnings : /nobackup/users/bowu/anaconda3/envs/mmf/lib/python3.6/site-packages/transformers/optimization.py:146: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /home/florin/anaconda3/conda-bld/pytorch-base_1604496080370/work/torch/csrc/utils/python_arg_parser.cpp:766.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)

2023-01-04T22:35:40 | WARNING | py.warnings : /nobackup/users/bowu/anaconda3/envs/mmf/lib/python3.6/site-packages/transformers/optimization.py:146: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /home/florin/anaconda3/conda-bld/pytorch-base_1604496080370/work/torch/csrc/utils/python_arg_parser.cpp:766.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)

2023-01-04T22:49:35 | INFO | mmf.trainers.callbacks.logistics : progress: 100/34000, star/train/masked_act_loss: 4.8180, star/train/masked_act_loss/avg: 4.8180, star/train/masked_obj1_loss: 0.7996, star/train/masked_obj1_loss/avg: 0.7996, star/train/masked_obj2_loss: 4.6012, star/train/masked_obj2_loss/avg: 4.6012, star/train/masked_rel_loss: 3.5177, star/train/masked_rel_loss/avg: 3.5177, train/total_loss: 13.7365, train/total_loss/avg: 13.7365, max mem: 3374.0, experiment: action_transition_model, epoch: 1, num_updates: 100, iterations: 100, max_updates: 34000, lr: 0.00002, ups: 0.12, time: 14m 04s 064ms, time_since_start: 14m 04s 090ms, eta: 79h 38m 30s 121ms
2023-01-04T23:02:11 | INFO | mmf.trainers.callbacks.logistics : progress: 200/34000, star/train/masked_act_loss: 4.3292, star/train/masked_act_loss/avg: 4.5736, star/train/masked_obj1_loss: 0.4995, star/train/masked_obj1_loss/avg: 0.6495, star/train/masked_obj2_loss: 3.8274, star/train/masked_obj2_loss/avg: 4.2143, star/train/masked_rel_loss: 2.7725, star/train/masked_rel_loss/avg: 3.1451, train/total_loss: 11.4286, train/total_loss/avg: 12.5826, max mem: 3374.0, experiment: action_transition_model, epoch: 2, num_updates: 200, iterations: 200, max_updates: 34000, lr: 0.00003, ups: 0.13, time: 12m 36s 728ms, time_since_start: 26m 40s 819ms, eta: 71h 11m 25s 751ms
2023-01-04T23:15:27 | INFO | mmf.trainers.callbacks.logistics : progress: 300/34000, star/train/masked_act_loss: 4.3292, star/train/masked_act_loss/avg: 4.3970, star/train/masked_obj1_loss: 0.4995, star/train/masked_obj1_loss/avg: 0.5764, star/train/masked_obj2_loss: 3.8274, star/train/masked_obj2_loss/avg: 3.9315, star/train/masked_rel_loss: 2.7725, star/train/masked_rel_loss/avg: 2.8810, train/total_loss: 11.4286, train/total_loss/avg: 11.7859, max mem: 3374.0, experiment: action_transition_model, epoch: 2, num_updates: 300, iterations: 300, max_updates: 34000, lr: 0.00004, ups: 0.13, time: 13m 15s 513ms, time_since_start: 39m 56s 332ms, eta: 74h 37m 04s 126ms
2023-01-04T23:29:14 | INFO | mmf.trainers.callbacks.logistics : progress: 400/34000, star/train/masked_act_loss: 4.0438, star/train/masked_act_loss/avg: 4.1579, star/train/masked_obj1_loss: 0.4302, star/train/masked_obj1_loss/avg: 0.5150, star/train/masked_obj2_loss: 3.3659, star/train/masked_obj2_loss/avg: 3.6803, star/train/masked_rel_loss: 2.3529, star/train/masked_rel_loss/avg: 2.6674, train/total_loss: 10.1927, train/total_loss/avg: 11.0206, max mem: 3374.0, experiment: action_transition_model, epoch: 3, num_updates: 400, iterations: 400, max_updates: 34000, lr: 0.00005, ups: 0.12, time: 13m 46s 758ms, time_since_start: 53m 43s 090ms, eta: 77h 19m 06s 375ms
2023-01-04T23:42:50 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-01-04T23:42:50 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

2023-01-04T23:42:50 | WARNING | py.warnings : /nobackup/users/bowu/code/STAR_code/STAR_Reasoning/NS-SR/mmf/mmf/utils/distributed.py:272: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.
  builtin_warn(*args, **kwargs)

2023-01-04T23:42:51 | INFO | mmf.trainers.callbacks.logistics : progress: 500/34000, star/train/masked_act_loss: 4.0438, star/train/masked_act_loss/avg: 3.9076, star/train/masked_obj1_loss: 0.4302, star/train/masked_obj1_loss/avg: 0.4718, star/train/masked_obj2_loss: 3.3659, star/train/masked_obj2_loss/avg: 3.4006, star/train/masked_rel_loss: 2.3529, star/train/masked_rel_loss/avg: 2.4893, train/total_loss: 10.1927, train/total_loss/avg: 10.2692, max mem: 3374.0, experiment: action_transition_model, epoch: 3, num_updates: 500, iterations: 500, max_updates: 34000, lr: 0.00006, ups: 0.12, time: 13m 37s 253ms, time_since_start: 01h 07m 20s 344ms, eta: 76h 12m 07s 362ms
2023-01-04T23:42:51 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-01-04T23:45:30 | INFO | mmf.trainers.callbacks.logistics : progress: 500/34000, star/val/masked_act_loss: 3.8050, star/val/masked_obj1_loss: 4.1842, star/val/masked_obj2_loss: 3.3862, star/val/masked_rel_loss: 4.2673, val/total_loss: 15.6427, val/star/mask_act_acc: 4.1068, val/star/mask_obj1_acc: 55.1303, val/star/mask_obj2_acc: 49.5742, val/star/mask_rel_acc: 48.2371, num_updates: 500, epoch: 3, iterations: 500, max_updates: 34000, val_time: 02m 39s 250ms, best_update: 500, best_iteration: 500, best_val/star/mask_act_acc: 4.106771
2023-01-04T23:59:35 | INFO | mmf.trainers.callbacks.logistics : progress: 600/34000, star/train/masked_act_loss: 3.4405, star/train/masked_act_loss/avg: 3.7480, star/train/masked_obj1_loss: 0.3308, star/train/masked_obj1_loss/avg: 0.4386, star/train/masked_obj2_loss: 2.9266, star/train/masked_obj2_loss/avg: 3.1804, star/train/masked_rel_loss: 2.0266, star/train/masked_rel_loss/avg: 2.3942, train/total_loss: 8.7245, train/total_loss/avg: 9.7612, max mem: 3379.0, experiment: action_transition_model, epoch: 4, num_updates: 600, iterations: 600, max_updates: 34000, lr: 0.00006, ups: 0.12, time: 14m 05s 072ms, time_since_start: 01h 24m 04s 668ms, eta: 78h 33m 38s 784ms
2023-01-05T00:12:01 | INFO | mmf.trainers.callbacks.logistics : progress: 700/34000, star/train/masked_act_loss: 3.4405, star/train/masked_act_loss/avg: 3.5733, star/train/masked_obj1_loss: 0.3308, star/train/masked_obj1_loss/avg: 0.4041, star/train/masked_obj2_loss: 2.9266, star/train/masked_obj2_loss/avg: 2.9921, star/train/masked_rel_loss: 2.0266, star/train/masked_rel_loss/avg: 2.3111, train/total_loss: 8.7245, train/total_loss/avg: 9.2807, max mem: 3379.0, experiment: action_transition_model, epoch: 5, num_updates: 700, iterations: 700, max_updates: 34000, lr: 0.00007, ups: 0.13, time: 12m 25s 763ms, time_since_start: 01h 36m 30s 432ms, eta: 69h 07m 15s 993ms
2023-01-05T00:25:44 | INFO | mmf.trainers.callbacks.logistics : progress: 800/34000, star/train/masked_act_loss: 2.9497, star/train/masked_act_loss/avg: 3.4006, star/train/masked_obj1_loss: 0.2988, star/train/masked_obj1_loss/avg: 0.3802, star/train/masked_obj2_loss: 2.2818, star/train/masked_obj2_loss/avg: 2.8347, star/train/masked_rel_loss: 1.9191, star/train/masked_rel_loss/avg: 2.2436, train/total_loss: 7.2638, train/total_loss/avg: 8.8591, max mem: 3379.0, experiment: action_transition_model, epoch: 5, num_updates: 800, iterations: 800, max_updates: 34000, lr: 0.00008, ups: 0.12, time: 13m 43s 480ms, time_since_start: 01h 50m 13s 912ms, eta: 76h 05m 42s 266ms
2023-01-05T00:39:04 | INFO | mmf.trainers.callbacks.logistics : progress: 900/34000, star/train/masked_act_loss: 2.9497, star/train/masked_act_loss/avg: 3.2640, star/train/masked_obj1_loss: 0.2988, star/train/masked_obj1_loss/avg: 0.3635, star/train/masked_obj2_loss: 2.2818, star/train/masked_obj2_loss/avg: 2.6939, star/train/masked_rel_loss: 1.9191, star/train/masked_rel_loss/avg: 2.1726, train/total_loss: 7.2638, train/total_loss/avg: 8.4939, max mem: 3379.0, experiment: action_transition_model, epoch: 6, num_updates: 900, iterations: 900, max_updates: 34000, lr: 0.00009, ups: 0.13, time: 13m 19s 591ms, time_since_start: 02h 03m 33s 504ms, eta: 73h 39m 54s 149ms
2023-01-05T00:52:35 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-01-05T00:52:36 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/34000, star/train/masked_act_loss: 2.9065, star/train/masked_act_loss/avg: 3.1722, star/train/masked_obj1_loss: 0.2728, star/train/masked_obj1_loss/avg: 0.3453, star/train/masked_obj2_loss: 2.0793, star/train/masked_obj2_loss/avg: 2.5708, star/train/masked_rel_loss: 1.8124, star/train/masked_rel_loss/avg: 2.1212, train/total_loss: 7.2210, train/total_loss/avg: 8.2095, max mem: 3379.0, experiment: action_transition_model, epoch: 6, num_updates: 1000, iterations: 1000, max_updates: 34000, lr: 0.0001, ups: 0.12, time: 13m 31s 643ms, time_since_start: 02h 17m 05s 147ms, eta: 74h 32m 58s 029ms
2023-01-05T00:52:36 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-01-05T00:55:09 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/34000, star/val/masked_act_loss: 3.2974, star/val/masked_obj1_loss: 4.8734, star/val/masked_obj2_loss: 4.0444, star/val/masked_rel_loss: 4.9452, val/total_loss: 17.1605, val/star/mask_act_acc: 5.5625, val/star/mask_obj1_acc: 43.0859, val/star/mask_obj2_acc: 47.0436, val/star/mask_rel_acc: 49.5988, num_updates: 1000, epoch: 6, iterations: 1000, max_updates: 34000, val_time: 02m 33s 208ms, best_update: 1000, best_iteration: 1000, best_val/star/mask_act_acc: 5.562500
2023-01-05T01:09:15 | INFO | mmf.trainers.callbacks.logistics : progress: 1100/34000, star/train/masked_act_loss: 2.9065, star/train/masked_act_loss/avg: 3.0662, star/train/masked_obj1_loss: 0.2728, star/train/masked_obj1_loss/avg: 0.3300, star/train/masked_obj2_loss: 2.0793, star/train/masked_obj2_loss/avg: 2.4757, star/train/masked_rel_loss: 1.8124, star/train/masked_rel_loss/avg: 2.0834, train/total_loss: 7.2210, train/total_loss/avg: 7.9553, max mem: 3379.0, experiment: action_transition_model, epoch: 7, num_updates: 1100, iterations: 1100, max_updates: 34000, lr: 0.0001, ups: 0.12, time: 14m 06s 177ms, time_since_start: 02h 33m 44s 534ms, eta: 77h 29m 09s 263ms
2023-01-05T01:22:21 | INFO | mmf.trainers.callbacks.logistics : progress: 1200/34000, star/train/masked_act_loss: 2.5253, star/train/masked_act_loss/avg: 2.9798, star/train/masked_obj1_loss: 0.2292, star/train/masked_obj1_loss/avg: 0.3163, star/train/masked_obj2_loss: 1.8628, star/train/masked_obj2_loss/avg: 2.4040, star/train/masked_rel_loss: 1.7766, star/train/masked_rel_loss/avg: 2.0508, train/total_loss: 6.3975, train/total_loss/avg: 7.7509, max mem: 3379.0, experiment: action_transition_model, epoch: 8, num_updates: 1200, iterations: 1200, max_updates: 34000, lr: 0.0001, ups: 0.13, time: 13m 05s 576ms, time_since_start: 02h 46m 50s 111ms, eta: 71h 43m 04s 406ms
2023-01-05T01:36:18 | INFO | mmf.trainers.callbacks.logistics : progress: 1300/34000, star/train/masked_act_loss: 2.5253, star/train/masked_act_loss/avg: 2.8947, star/train/masked_obj1_loss: 0.2292, star/train/masked_obj1_loss/avg: 0.3093, star/train/masked_obj2_loss: 1.8628, star/train/masked_obj2_loss/avg: 2.3257, star/train/masked_rel_loss: 1.7766, star/train/masked_rel_loss/avg: 2.0154, train/total_loss: 6.3975, train/total_loss/avg: 7.5451, max mem: 3379.0, experiment: action_transition_model, epoch: 8, num_updates: 1300, iterations: 1300, max_updates: 34000, lr: 0.0001, ups: 0.12, time: 13m 56s 955ms, time_since_start: 03h 47s 067ms, eta: 76h 10m 31s 960ms
2023-01-05T01:50:31 | INFO | mmf.trainers.callbacks.logistics : progress: 1400/34000, star/train/masked_act_loss: 2.3459, star/train/masked_act_loss/avg: 2.8314, star/train/masked_obj1_loss: 0.2253, star/train/masked_obj1_loss/avg: 0.3001, star/train/masked_obj2_loss: 1.7324, star/train/masked_obj2_loss/avg: 2.2708, star/train/masked_rel_loss: 1.7710, star/train/masked_rel_loss/avg: 1.9862, train/total_loss: 5.9084, train/total_loss/avg: 7.3884, max mem: 3379.0, experiment: action_transition_model, epoch: 9, num_updates: 1400, iterations: 1400, max_updates: 34000, lr: 0.0001, ups: 0.12, time: 14m 13s 713ms, time_since_start: 03h 15m 780ms, eta: 77h 27m 47s 302ms
2023-01-05T02:04:54 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-01-05T02:04:54 | INFO | mmf.trainers.callbacks.logistics : progress: 1500/34000, star/train/masked_act_loss: 2.3459, star/train/masked_act_loss/avg: 2.7686, star/train/masked_obj1_loss: 0.2253, star/train/masked_obj1_loss/avg: 0.2911, star/train/masked_obj2_loss: 1.7324, star/train/masked_obj2_loss/avg: 2.2153, star/train/masked_rel_loss: 1.7710, star/train/masked_rel_loss/avg: 1.9552, train/total_loss: 5.9084, train/total_loss/avg: 7.2302, max mem: 3379.0, experiment: action_transition_model, epoch: 9, num_updates: 1500, iterations: 1500, max_updates: 34000, lr: 0.0001, ups: 0.12, time: 14m 22s 733ms, time_since_start: 03h 29m 23s 514ms, eta: 78h 02m 29s 092ms
2023-01-05T02:04:54 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-01-05T02:08:07 | INFO | mmf.trainers.callbacks.logistics : progress: 1500/34000, star/val/masked_act_loss: 3.2557, star/val/masked_obj1_loss: 4.9908, star/val/masked_obj2_loss: 4.2316, star/val/masked_rel_loss: 5.2839, val/total_loss: 17.7620, val/star/mask_act_acc: 5.7292, val/star/mask_obj1_acc: 48.5396, val/star/mask_obj2_acc: 47.4759, val/star/mask_rel_acc: 46.5552, num_updates: 1500, epoch: 9, iterations: 1500, max_updates: 34000, val_time: 03m 12s 477ms, best_update: 1500, best_iteration: 1500, best_val/star/mask_act_acc: 5.729167
2023-01-05T02:24:08 | INFO | mmf.trainers.callbacks.logistics : progress: 1600/34000, star/train/masked_act_loss: 2.1919, star/train/masked_act_loss/avg: 2.7051, star/train/masked_obj1_loss: 0.2132, star/train/masked_obj1_loss/avg: 0.2825, star/train/masked_obj2_loss: 1.6162, star/train/masked_obj2_loss/avg: 2.1704, star/train/masked_rel_loss: 1.7056, star/train/masked_rel_loss/avg: 1.9250, train/total_loss: 5.6492, train/total_loss/avg: 7.0829, max mem: 3379.0, experiment: action_transition_model, epoch: 10, num_updates: 1600, iterations: 1600, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 01s 864ms, time_since_start: 03h 48m 37s 857ms, eta: 86h 44m 27s 481ms
2023-01-05T02:40:41 | INFO | mmf.trainers.callbacks.logistics : progress: 1700/34000, star/train/masked_act_loss: 2.1919, star/train/masked_act_loss/avg: 2.6570, star/train/masked_obj1_loss: 0.2244, star/train/masked_obj1_loss/avg: 0.2796, star/train/masked_obj2_loss: 1.6162, star/train/masked_obj2_loss/avg: 2.1312, star/train/masked_rel_loss: 1.7056, star/train/masked_rel_loss/avg: 1.9008, train/total_loss: 5.6492, train/total_loss/avg: 6.9686, max mem: 3379.0, experiment: action_transition_model, epoch: 10, num_updates: 1700, iterations: 1700, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 32s 680ms, time_since_start: 04h 05m 10s 537ms, eta: 89h 14m 37s 006ms
2023-01-05T02:56:43 | INFO | mmf.trainers.callbacks.logistics : progress: 1800/34000, star/train/masked_act_loss: 2.1711, star/train/masked_act_loss/avg: 2.6081, star/train/masked_obj1_loss: 0.2132, star/train/masked_obj1_loss/avg: 0.2704, star/train/masked_obj2_loss: 1.5678, star/train/masked_obj2_loss/avg: 2.0923, star/train/masked_rel_loss: 1.6917, star/train/masked_rel_loss/avg: 1.8770, train/total_loss: 5.5725, train/total_loss/avg: 6.8478, max mem: 3379.0, experiment: action_transition_model, epoch: 11, num_updates: 1800, iterations: 1800, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 01s 662ms, time_since_start: 04h 21m 12s 200ms, eta: 86h 11m 14s 746ms
2023-01-05T03:11:51 | INFO | mmf.trainers.callbacks.logistics : progress: 1900/34000, star/train/masked_act_loss: 2.1711, star/train/masked_act_loss/avg: 2.5539, star/train/masked_obj1_loss: 0.2132, star/train/masked_obj1_loss/avg: 0.2607, star/train/masked_obj2_loss: 1.5678, star/train/masked_obj2_loss/avg: 2.0532, star/train/masked_rel_loss: 1.6917, star/train/masked_rel_loss/avg: 1.8605, train/total_loss: 5.5725, train/total_loss/avg: 6.7283, max mem: 3379.0, experiment: action_transition_model, epoch: 12, num_updates: 1900, iterations: 1900, max_updates: 34000, lr: 0.0001, ups: 0.11, time: 15m 08s 197ms, time_since_start: 04h 36m 20s 398ms, eta: 81h 08m 34s 497ms
2023-01-05T03:27:58 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-01-05T03:27:59 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/34000, star/train/masked_act_loss: 2.0287, star/train/masked_act_loss/avg: 2.5146, star/train/masked_obj1_loss: 0.1971, star/train/masked_obj1_loss/avg: 0.2532, star/train/masked_obj2_loss: 1.5567, star/train/masked_obj2_loss/avg: 2.0116, star/train/masked_rel_loss: 1.6588, star/train/masked_rel_loss/avg: 1.8391, train/total_loss: 5.5032, train/total_loss/avg: 6.6184, max mem: 3379.0, experiment: action_transition_model, epoch: 12, num_updates: 2000, iterations: 2000, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 07s 710ms, time_since_start: 04h 52m 28s 109ms, eta: 86h 11m 26s 861ms
2023-01-05T03:27:59 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-01-05T03:31:12 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/34000, star/val/masked_act_loss: 3.4557, star/val/masked_obj1_loss: 5.3643, star/val/masked_obj2_loss: 4.5855, star/val/masked_rel_loss: 5.5447, val/total_loss: 18.9502, val/star/mask_act_acc: 5.6758, val/star/mask_obj1_acc: 45.0246, val/star/mask_obj2_acc: 46.7975, val/star/mask_rel_acc: 46.9571, num_updates: 2000, epoch: 12, iterations: 2000, max_updates: 34000, val_time: 03m 13s 492ms, best_update: 1500, best_iteration: 1500, best_val/star/mask_act_acc: 5.729167
2023-01-05T03:47:03 | INFO | mmf.trainers.callbacks.logistics : progress: 2100/34000, star/train/masked_act_loss: 2.0086, star/train/masked_act_loss/avg: 2.4696, star/train/masked_obj1_loss: 0.1821, star/train/masked_obj1_loss/avg: 0.2443, star/train/masked_obj2_loss: 1.5247, star/train/masked_obj2_loss/avg: 1.9747, star/train/masked_rel_loss: 1.6062, star/train/masked_rel_loss/avg: 1.8222, train/total_loss: 5.4132, train/total_loss/avg: 6.5108, max mem: 3379.0, experiment: action_transition_model, epoch: 13, num_updates: 2100, iterations: 2100, max_updates: 34000, lr: 0.0001, ups: 0.11, time: 15m 51s 340ms, time_since_start: 05h 11m 32s 942ms, eta: 84h 28m 04s 492ms
2023-01-05T04:02:56 | INFO | mmf.trainers.callbacks.logistics : progress: 2200/34000, star/train/masked_act_loss: 2.0066, star/train/masked_act_loss/avg: 2.4327, star/train/masked_obj1_loss: 0.1793, star/train/masked_obj1_loss/avg: 0.2357, star/train/masked_obj2_loss: 1.4964, star/train/masked_obj2_loss/avg: 1.9446, star/train/masked_rel_loss: 1.6043, star/train/masked_rel_loss/avg: 1.8034, train/total_loss: 5.3510, train/total_loss/avg: 6.4165, max mem: 3379.0, experiment: action_transition_model, epoch: 13, num_updates: 2200, iterations: 2200, max_updates: 34000, lr: 0.0001, ups: 0.11, time: 15m 52s 141ms, time_since_start: 05h 27m 25s 084ms, eta: 84h 16m 26s 631ms
2023-01-05T04:18:34 | INFO | mmf.trainers.callbacks.logistics : progress: 2300/34000, star/train/masked_act_loss: 1.8896, star/train/masked_act_loss/avg: 2.3866, star/train/masked_obj1_loss: 0.1763, star/train/masked_obj1_loss/avg: 0.2295, star/train/masked_obj2_loss: 1.4624, star/train/masked_obj2_loss/avg: 1.9168, star/train/masked_rel_loss: 1.5910, star/train/masked_rel_loss/avg: 1.7919, train/total_loss: 5.0756, train/total_loss/avg: 6.3248, max mem: 3379.0, experiment: action_transition_model, epoch: 14, num_updates: 2300, iterations: 2300, max_updates: 34000, lr: 0.0001, ups: 0.11, time: 15m 38s 442ms, time_since_start: 05h 43m 03s 526ms, eta: 82h 48m 01s 210ms
2023-01-05T04:34:38 | INFO | mmf.trainers.callbacks.logistics : progress: 2400/34000, star/train/masked_act_loss: 1.8739, star/train/masked_act_loss/avg: 2.3531, star/train/masked_obj1_loss: 0.1665, star/train/masked_obj1_loss/avg: 0.2218, star/train/masked_obj2_loss: 1.4387, star/train/masked_obj2_loss/avg: 1.8811, star/train/masked_rel_loss: 1.5658, star/train/masked_rel_loss/avg: 1.7750, train/total_loss: 5.0158, train/total_loss/avg: 6.2309, max mem: 3379.0, experiment: action_transition_model, epoch: 15, num_updates: 2400, iterations: 2400, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 03s 525ms, time_since_start: 05h 59m 07s 052ms, eta: 84h 44m 43s 126ms
2023-01-05T04:50:42 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-01-05T04:50:42 | INFO | mmf.trainers.callbacks.logistics : progress: 2500/34000, star/train/masked_act_loss: 1.7851, star/train/masked_act_loss/avg: 2.3126, star/train/masked_obj1_loss: 0.1656, star/train/masked_obj1_loss/avg: 0.2139, star/train/masked_obj2_loss: 1.4380, star/train/masked_obj2_loss/avg: 1.8513, star/train/masked_rel_loss: 1.5406, star/train/masked_rel_loss/avg: 1.7614, train/total_loss: 4.8736, train/total_loss/avg: 6.1392, max mem: 3379.0, experiment: action_transition_model, epoch: 15, num_updates: 2500, iterations: 2500, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 04s 876ms, time_since_start: 06h 15m 11s 929ms, eta: 84h 35m 44s 125ms
2023-01-05T04:50:42 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-01-05T04:54:04 | INFO | mmf.trainers.callbacks.logistics : progress: 2500/34000, star/val/masked_act_loss: 3.5447, star/val/masked_obj1_loss: 5.6300, star/val/masked_obj2_loss: 4.8619, star/val/masked_rel_loss: 5.9469, val/total_loss: 19.9836, val/star/mask_act_acc: 6.3542, val/star/mask_obj1_acc: 43.8137, val/star/mask_obj2_acc: 46.0859, val/star/mask_rel_acc: 43.3657, num_updates: 2500, epoch: 15, iterations: 2500, max_updates: 34000, val_time: 03m 21s 730ms, best_update: 2500, best_iteration: 2500, best_val/star/mask_act_acc: 6.354167
2023-01-05T05:09:43 | INFO | mmf.trainers.callbacks.logistics : progress: 2600/34000, star/train/masked_act_loss: 1.7745, star/train/masked_act_loss/avg: 2.2820, star/train/masked_obj1_loss: 0.1536, star/train/masked_obj1_loss/avg: 0.2064, star/train/masked_obj2_loss: 1.3854, star/train/masked_obj2_loss/avg: 1.8257, star/train/masked_rel_loss: 1.5219, star/train/masked_rel_loss/avg: 1.7491, train/total_loss: 4.8146, train/total_loss/avg: 6.0632, max mem: 3379.0, experiment: action_transition_model, epoch: 16, num_updates: 2600, iterations: 2600, max_updates: 34000, lr: 0.0001, ups: 0.11, time: 15m 38s 861ms, time_since_start: 06h 34m 12s 522ms, eta: 82h 03m 12s 032ms
2023-01-05T05:25:35 | INFO | mmf.trainers.callbacks.logistics : progress: 2700/34000, star/train/masked_act_loss: 1.7521, star/train/masked_act_loss/avg: 2.2428, star/train/masked_obj1_loss: 0.1144, star/train/masked_obj1_loss/avg: 0.1998, star/train/masked_obj2_loss: 1.3786, star/train/masked_obj2_loss/avg: 1.7980, star/train/masked_rel_loss: 1.4859, star/train/masked_rel_loss/avg: 1.7353, train/total_loss: 4.7723, train/total_loss/avg: 5.9758, max mem: 3379.0, experiment: action_transition_model, epoch: 16, num_updates: 2700, iterations: 2700, max_updates: 34000, lr: 0.0001, ups: 0.11, time: 15m 51s 915ms, time_since_start: 06h 50m 04s 438ms, eta: 82h 55m 45s 438ms
2023-01-05T05:41:17 | INFO | mmf.trainers.callbacks.logistics : progress: 2800/34000, star/train/masked_act_loss: 1.7331, star/train/masked_act_loss/avg: 2.2021, star/train/masked_obj1_loss: 0.1118, star/train/masked_obj1_loss/avg: 0.1935, star/train/masked_obj2_loss: 1.3569, star/train/masked_obj2_loss/avg: 1.7721, star/train/masked_rel_loss: 1.4859, star/train/masked_rel_loss/avg: 1.7268, train/total_loss: 4.5976, train/total_loss/avg: 5.8944, max mem: 3379.0, experiment: action_transition_model, epoch: 17, num_updates: 2800, iterations: 2800, max_updates: 34000, lr: 0.0001, ups: 0.11, time: 15m 42s 467ms, time_since_start: 07h 05m 46s 905ms, eta: 81h 50m 37s 917ms
2023-01-05T05:57:35 | INFO | mmf.trainers.callbacks.logistics : progress: 2900/34000, star/train/masked_act_loss: 1.6645, star/train/masked_act_loss/avg: 2.1671, star/train/masked_obj1_loss: 0.0926, star/train/masked_obj1_loss/avg: 0.1872, star/train/masked_obj2_loss: 1.3177, star/train/masked_obj2_loss/avg: 1.7479, star/train/masked_rel_loss: 1.4772, star/train/masked_rel_loss/avg: 1.7164, train/total_loss: 4.5496, train/total_loss/avg: 5.8188, max mem: 3379.0, experiment: action_transition_model, epoch: 18, num_updates: 2900, iterations: 2900, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 17s 401ms, time_since_start: 07h 22m 04s 306ms, eta: 84h 36m 19s 707ms
2023-01-05T06:13:15 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-01-05T06:13:15 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/34000, star/train/masked_act_loss: 1.5873, star/train/masked_act_loss/avg: 2.1346, star/train/masked_obj1_loss: 0.0882, star/train/masked_obj1_loss/avg: 0.1814, star/train/masked_obj2_loss: 1.3103, star/train/masked_obj2_loss/avg: 1.7267, star/train/masked_rel_loss: 1.4715, star/train/masked_rel_loss/avg: 1.7079, train/total_loss: 4.4516, train/total_loss/avg: 5.7506, max mem: 3379.0, experiment: action_transition_model, epoch: 18, num_updates: 3000, iterations: 3000, max_updates: 34000, lr: 0.0001, ups: 0.11, time: 15m 40s 316ms, time_since_start: 07h 37m 44s 623ms, eta: 81h 08m 01s 194ms
2023-01-05T06:13:15 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-01-05T06:16:19 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/34000, star/val/masked_act_loss: 3.7919, star/val/masked_obj1_loss: 5.7184, star/val/masked_obj2_loss: 4.9787, star/val/masked_rel_loss: 5.9550, val/total_loss: 20.4440, val/star/mask_act_acc: 5.8346, val/star/mask_obj1_acc: 44.6408, val/star/mask_obj2_acc: 46.0853, val/star/mask_rel_acc: 47.0368, num_updates: 3000, epoch: 18, iterations: 3000, max_updates: 34000, val_time: 03m 03s 660ms, best_update: 2500, best_iteration: 2500, best_val/star/mask_act_acc: 6.354167
2023-01-05T06:32:12 | INFO | mmf.trainers.callbacks.logistics : progress: 3100/34000, star/train/masked_act_loss: 1.5867, star/train/masked_act_loss/avg: 2.1000, star/train/masked_obj1_loss: 0.0692, star/train/masked_obj1_loss/avg: 0.1769, star/train/masked_obj2_loss: 1.2432, star/train/masked_obj2_loss/avg: 1.7066, star/train/masked_rel_loss: 1.4615, star/train/masked_rel_loss/avg: 1.6985, train/total_loss: 4.3760, train/total_loss/avg: 5.6820, max mem: 3379.0, experiment: action_transition_model, epoch: 19, num_updates: 3100, iterations: 3100, max_updates: 34000, lr: 0.0001, ups: 0.11, time: 15m 52s 883ms, time_since_start: 07h 56m 41s 168ms, eta: 81h 57m 09s 940ms
2023-01-05T06:48:27 | INFO | mmf.trainers.callbacks.logistics : progress: 3200/34000, star/train/masked_act_loss: 1.5777, star/train/masked_act_loss/avg: 2.0615, star/train/masked_obj1_loss: 0.0564, star/train/masked_obj1_loss/avg: 0.1722, star/train/masked_obj2_loss: 1.2270, star/train/masked_obj2_loss/avg: 1.6862, star/train/masked_rel_loss: 1.4449, star/train/masked_rel_loss/avg: 1.6902, train/total_loss: 4.3232, train/total_loss/avg: 5.6100, max mem: 3379.0, experiment: action_transition_model, epoch: 19, num_updates: 3200, iterations: 3200, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 15s 482ms, time_since_start: 08h 12m 56s 651ms, eta: 83h 37m 29s 495ms
2023-01-05T07:04:20 | INFO | mmf.trainers.callbacks.logistics : progress: 3300/34000, star/train/masked_act_loss: 1.5207, star/train/masked_act_loss/avg: 2.0295, star/train/masked_obj1_loss: 0.0459, star/train/masked_obj1_loss/avg: 0.1679, star/train/masked_obj2_loss: 1.1906, star/train/masked_obj2_loss/avg: 1.6690, star/train/masked_rel_loss: 1.4363, star/train/masked_rel_loss/avg: 1.6807, train/total_loss: 4.1758, train/total_loss/avg: 5.5471, max mem: 3379.0, experiment: action_transition_model, epoch: 20, num_updates: 3300, iterations: 3300, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 15m 53s 034ms, time_since_start: 08h 28m 49s 686ms, eta: 81h 26m 06s 828ms
2023-01-05T07:20:05 | INFO | mmf.trainers.callbacks.logistics : progress: 3400/34000, star/train/masked_act_loss: 1.3797, star/train/masked_act_loss/avg: 2.0082, star/train/masked_obj1_loss: 0.0435, star/train/masked_obj1_loss/avg: 0.1644, star/train/masked_obj2_loss: 1.1414, star/train/masked_obj2_loss/avg: 1.6559, star/train/masked_rel_loss: 1.4363, star/train/masked_rel_loss/avg: 1.6736, train/total_loss: 4.0875, train/total_loss/avg: 5.5021, max mem: 3379.0, experiment: action_transition_model, epoch: 20, num_updates: 3400, iterations: 3400, max_updates: 34000, lr: 0.0001, ups: 0.11, time: 15m 44s 895ms, time_since_start: 08h 44m 34s 581ms, eta: 80h 28m 36s 197ms
2023-01-05T07:36:19 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-01-05T07:36:20 | INFO | mmf.trainers.callbacks.logistics : progress: 3500/34000, star/train/masked_act_loss: 1.3485, star/train/masked_act_loss/avg: 1.9832, star/train/masked_obj1_loss: 0.0300, star/train/masked_obj1_loss/avg: 0.1598, star/train/masked_obj2_loss: 1.1397, star/train/masked_obj2_loss/avg: 1.6384, star/train/masked_rel_loss: 1.4362, star/train/masked_rel_loss/avg: 1.6626, train/total_loss: 3.9528, train/total_loss/avg: 5.4440, max mem: 3379.0, experiment: action_transition_model, epoch: 21, num_updates: 3500, iterations: 3500, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 14s 819ms, time_since_start: 09h 49s 401ms, eta: 82h 45m 14s 717ms
2023-01-05T07:36:20 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-01-05T07:39:22 | INFO | mmf.trainers.callbacks.logistics : progress: 3500/34000, star/val/masked_act_loss: 3.9677, star/val/masked_obj1_loss: 5.8559, star/val/masked_obj2_loss: 5.1056, star/val/masked_rel_loss: 6.2618, val/total_loss: 21.1909, val/star/mask_act_acc: 5.4583, val/star/mask_obj1_acc: 42.9298, val/star/mask_obj2_acc: 45.9023, val/star/mask_rel_acc: 44.2178, num_updates: 3500, epoch: 21, iterations: 3500, max_updates: 34000, val_time: 03m 01s 901ms, best_update: 2500, best_iteration: 2500, best_val/star/mask_act_acc: 6.354167
2023-01-05T07:55:38 | INFO | mmf.trainers.callbacks.logistics : progress: 3600/34000, star/train/masked_act_loss: 1.2303, star/train/masked_act_loss/avg: 1.9508, star/train/masked_obj1_loss: 0.0292, star/train/masked_obj1_loss/avg: 0.1557, star/train/masked_obj2_loss: 1.1223, star/train/masked_obj2_loss/avg: 1.6209, star/train/masked_rel_loss: 1.4351, star/train/masked_rel_loss/avg: 1.6545, train/total_loss: 3.7859, train/total_loss/avg: 5.3818, max mem: 3379.0, experiment: action_transition_model, epoch: 22, num_updates: 3600, iterations: 3600, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 16s 028ms, time_since_start: 09h 20m 07s 331ms, eta: 82h 35m 05s 983ms
2023-01-05T08:11:00 | INFO | mmf.trainers.callbacks.logistics : progress: 3700/34000, star/train/masked_act_loss: 1.1969, star/train/masked_act_loss/avg: 1.9206, star/train/masked_obj1_loss: 0.0268, star/train/masked_obj1_loss/avg: 0.1517, star/train/masked_obj2_loss: 1.1145, star/train/masked_obj2_loss/avg: 1.6031, star/train/masked_rel_loss: 1.4289, star/train/masked_rel_loss/avg: 1.6463, train/total_loss: 3.7292, train/total_loss/avg: 5.3217, max mem: 3379.0, experiment: action_transition_model, epoch: 22, num_updates: 3700, iterations: 3700, max_updates: 34000, lr: 0.0001, ups: 0.11, time: 15m 21s 898ms, time_since_start: 09h 35m 29s 229ms, eta: 77h 44m 53s 835ms
2023-01-05T08:26:52 | INFO | mmf.trainers.callbacks.logistics : progress: 3800/34000, star/train/masked_act_loss: 1.1945, star/train/masked_act_loss/avg: 1.8922, star/train/masked_obj1_loss: 0.0266, star/train/masked_obj1_loss/avg: 0.1481, star/train/masked_obj2_loss: 1.1074, star/train/masked_obj2_loss/avg: 1.5891, star/train/masked_rel_loss: 1.4175, star/train/masked_rel_loss/avg: 1.6393, train/total_loss: 3.7171, train/total_loss/avg: 5.2687, max mem: 3379.0, experiment: action_transition_model, epoch: 23, num_updates: 3800, iterations: 3800, max_updates: 34000, lr: 0.0001, ups: 0.11, time: 15m 51s 885ms, time_since_start: 09h 51m 21s 115ms, eta: 80h 44s 497ms
2023-01-05T08:43:15 | INFO | mmf.trainers.callbacks.logistics : progress: 3900/34000, star/train/masked_act_loss: 1.1698, star/train/masked_act_loss/avg: 1.8663, star/train/masked_obj1_loss: 0.0266, star/train/masked_obj1_loss/avg: 0.1453, star/train/masked_obj2_loss: 1.0951, star/train/masked_obj2_loss/avg: 1.5763, star/train/masked_rel_loss: 1.4130, star/train/masked_rel_loss/avg: 1.6316, train/total_loss: 3.7144, train/total_loss/avg: 5.2195, max mem: 3379.0, experiment: action_transition_model, epoch: 23, num_updates: 3900, iterations: 3900, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 22s 876ms, time_since_start: 10h 07m 43s 992ms, eta: 82h 20m 37s 539ms
2023-01-05T09:00:02 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-01-05T09:00:03 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/34000, star/train/masked_act_loss: 1.1427, star/train/masked_act_loss/avg: 1.8388, star/train/masked_obj1_loss: 0.0255, star/train/masked_obj1_loss/avg: 0.1422, star/train/masked_obj2_loss: 1.0908, star/train/masked_obj2_loss/avg: 1.5641, star/train/masked_rel_loss: 1.4130, star/train/masked_rel_loss/avg: 1.6271, train/total_loss: 3.7102, train/total_loss/avg: 5.1721, max mem: 3379.0, experiment: action_transition_model, epoch: 24, num_updates: 4000, iterations: 4000, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 48s 143ms, time_since_start: 10h 24m 32s 135ms, eta: 84h 10m 47s 911ms
2023-01-05T09:00:03 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-01-05T09:03:26 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/34000, star/val/masked_act_loss: 4.1997, star/val/masked_obj1_loss: 5.9932, star/val/masked_obj2_loss: 5.2321, star/val/masked_rel_loss: 6.4645, val/total_loss: 21.8895, val/star/mask_act_acc: 5.8372, val/star/mask_obj1_acc: 43.0221, val/star/mask_obj2_acc: 46.0254, val/star/mask_rel_acc: 45.7910, num_updates: 4000, epoch: 24, iterations: 4000, max_updates: 34000, val_time: 03m 23s 081ms, best_update: 2500, best_iteration: 2500, best_val/star/mask_act_acc: 6.354167
2023-01-05T09:19:48 | INFO | mmf.trainers.callbacks.logistics : progress: 4100/34000, star/train/masked_act_loss: 1.1105, star/train/masked_act_loss/avg: 1.8159, star/train/masked_obj1_loss: 0.0239, star/train/masked_obj1_loss/avg: 0.1388, star/train/masked_obj2_loss: 1.0808, star/train/masked_obj2_loss/avg: 1.5516, star/train/masked_rel_loss: 1.3942, star/train/masked_rel_loss/avg: 1.6176, train/total_loss: 3.6352, train/total_loss/avg: 5.1239, max mem: 3379.0, experiment: action_transition_model, epoch: 25, num_updates: 4100, iterations: 4100, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 22s 469ms, time_since_start: 10h 44m 17s 687ms, eta: 81h 45m 45s 814ms
2023-01-05T09:35:56 | INFO | mmf.trainers.callbacks.logistics : progress: 4200/34000, star/train/masked_act_loss: 1.0668, star/train/masked_act_loss/avg: 1.7867, star/train/masked_obj1_loss: 0.0239, star/train/masked_obj1_loss/avg: 0.1365, star/train/masked_obj2_loss: 1.0773, star/train/masked_obj2_loss/avg: 1.5385, star/train/masked_rel_loss: 1.3895, star/train/masked_rel_loss/avg: 1.6120, train/total_loss: 3.5425, train/total_loss/avg: 5.0737, max mem: 3379.0, experiment: action_transition_model, epoch: 25, num_updates: 4200, iterations: 4200, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 08s 255ms, time_since_start: 11h 25s 943ms, eta: 80h 18m 37s 301ms
2023-01-05T09:52:20 | INFO | mmf.trainers.callbacks.logistics : progress: 4300/34000, star/train/masked_act_loss: 1.0106, star/train/masked_act_loss/avg: 1.7598, star/train/masked_obj1_loss: 0.0239, star/train/masked_obj1_loss/avg: 0.1340, star/train/masked_obj2_loss: 1.0767, star/train/masked_obj2_loss/avg: 1.5253, star/train/masked_rel_loss: 1.3837, star/train/masked_rel_loss/avg: 1.6032, train/total_loss: 3.4896, train/total_loss/avg: 5.0222, max mem: 3379.0, experiment: action_transition_model, epoch: 26, num_updates: 4300, iterations: 4300, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 23s 653ms, time_since_start: 11h 16m 49s 596ms, eta: 81h 18m 49s 482ms
2023-01-05T10:08:48 | INFO | mmf.trainers.callbacks.logistics : progress: 4400/34000, star/train/masked_act_loss: 0.9081, star/train/masked_act_loss/avg: 1.7359, star/train/masked_obj1_loss: 0.0211, star/train/masked_obj1_loss/avg: 0.1312, star/train/masked_obj2_loss: 1.0767, star/train/masked_obj2_loss/avg: 1.5123, star/train/masked_rel_loss: 1.3795, star/train/masked_rel_loss/avg: 1.5935, train/total_loss: 3.3911, train/total_loss/avg: 4.9728, max mem: 3379.0, experiment: action_transition_model, epoch: 26, num_updates: 4400, iterations: 4400, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 28s 350ms, time_since_start: 11h 33m 17s 947ms, eta: 81h 25m 36s 779ms
2023-01-05T10:25:17 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-01-05T10:25:17 | INFO | mmf.trainers.callbacks.logistics : progress: 4500/34000, star/train/masked_act_loss: 0.8892, star/train/masked_act_loss/avg: 1.7134, star/train/masked_obj1_loss: 0.0196, star/train/masked_obj1_loss/avg: 0.1285, star/train/masked_obj2_loss: 1.0752, star/train/masked_obj2_loss/avg: 1.4979, star/train/masked_rel_loss: 1.3791, star/train/masked_rel_loss/avg: 1.5869, train/total_loss: 3.3662, train/total_loss/avg: 4.9267, max mem: 3379.0, experiment: action_transition_model, epoch: 27, num_updates: 4500, iterations: 4500, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 28s 654ms, time_since_start: 11h 49m 46s 601ms, eta: 81h 10m 36s 414ms
2023-01-05T10:25:17 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-01-05T10:28:40 | INFO | mmf.trainers.callbacks.logistics : progress: 4500/34000, star/val/masked_act_loss: 4.3737, star/val/masked_obj1_loss: 6.1639, star/val/masked_obj2_loss: 5.3696, star/val/masked_rel_loss: 6.5851, val/total_loss: 22.4924, val/star/mask_act_acc: 5.6484, val/star/mask_obj1_acc: 41.8490, val/star/mask_obj2_acc: 45.8203, val/star/mask_rel_acc: 44.1365, num_updates: 4500, epoch: 27, iterations: 4500, max_updates: 34000, val_time: 03m 23s 331ms, best_update: 2500, best_iteration: 2500, best_val/star/mask_act_acc: 6.354167
2023-01-05T10:45:22 | INFO | mmf.trainers.callbacks.logistics : progress: 4600/34000, star/train/masked_act_loss: 0.8736, star/train/masked_act_loss/avg: 1.6918, star/train/masked_obj1_loss: 0.0211, star/train/masked_obj1_loss/avg: 0.1263, star/train/masked_obj2_loss: 1.0560, star/train/masked_obj2_loss/avg: 1.4861, star/train/masked_rel_loss: 1.3769, star/train/masked_rel_loss/avg: 1.5815, train/total_loss: 3.3413, train/total_loss/avg: 4.8856, max mem: 3379.0, experiment: action_transition_model, epoch: 28, num_updates: 4600, iterations: 4600, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 41s 319ms, time_since_start: 12h 09m 51s 254ms, eta: 81h 56m 16s 789ms
2023-01-05T11:02:01 | INFO | mmf.trainers.callbacks.logistics : progress: 4700/34000, star/train/masked_act_loss: 0.8517, star/train/masked_act_loss/avg: 1.6706, star/train/masked_obj1_loss: 0.0208, star/train/masked_obj1_loss/avg: 0.1240, star/train/masked_obj2_loss: 1.0556, star/train/masked_obj2_loss/avg: 1.4753, star/train/masked_rel_loss: 1.3748, star/train/masked_rel_loss/avg: 1.5741, train/total_loss: 3.3249, train/total_loss/avg: 4.8441, max mem: 3379.0, experiment: action_transition_model, epoch: 28, num_updates: 4700, iterations: 4700, max_updates: 34000, lr: 0.0001, ups: 0.10, time: 16m 39s 030ms, time_since_start: 12h 26m 30s 285ms, eta: 81h 28m 21s 410ms
